{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Wake Word Detection - Threshold Sweep Analysis\n",
        "\n",
        "This notebook performs a systematic sweep across different detection thresholds to analyze model performance on negative samples."
      ],
      "metadata": {
        "id": "notebook_title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup - Mount Google Drive"
      ],
      "metadata": {
        "id": "section_mount"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mount_drive",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a370a28-1750-4fe9-f201-a74ace1fa1f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Install Dependencies"
      ],
      "metadata": {
        "id": "section_install"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openwakeword numpy"
      ],
      "metadata": {
        "id": "install_deps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb04101e-bba8-4675-a2a3-72aca4d132af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openwakeword in /usr/local/lib/python3.12/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from openwakeword) (1.23.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.0 in /usr/local/lib/python3.12/dist-packages (from openwakeword) (4.67.1)\n",
            "Requirement already satisfied: scipy<2,>=1.3 in /usr/local/lib/python3.12/dist-packages (from openwakeword) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.12/dist-packages (from openwakeword) (1.6.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword) (1.14.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2,>=1->openwakeword) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2,>=1->openwakeword) (3.6.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<2,>=1.10.0->openwakeword) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.10.0->openwakeword) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Import Libraries"
      ],
      "metadata": {
        "id": "section_imports"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import wave\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Optional, List, Dict\n",
        "\n",
        "import numpy as np\n",
        "from openwakeword.model import Model"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Configuration Parameters\n",
        "\n",
        "**Update these paths after uploading your files to Google Drive**"
      ],
      "metadata": {
        "id": "section_config"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PATHS - UPDATE THESE AFTER UPLOADING TO GOOGLE DRIVE\n",
        "# ============================================================\n",
        "\n",
        "# Path to your negative wavs (either a zip file or a directory)\n",
        "NEGATIVE_WAVS_PATH = \"/content/drive/MyDrive/curve_sweep/neg_wavs.zip\"  # UPDATE THIS\n",
        "\n",
        "# Path to your model\n",
        "MODEL_PATH = \"/content/drive/MyDrive/curve_sweep/how_you_do_this.onnx\"  # UPDATE THIS\n",
        "\n",
        "# Output CSV path in Google Drive\n",
        "OUTPUT_CSV_PATH = \"/content/drive/My Drive/threshold_sweep_results.csv\"  # UPDATE IF NEEDED\n",
        "\n",
        "# ============================================================\n",
        "# SWEEP PARAMETERS\n",
        "# ============================================================\n",
        "\n",
        "# Thresholds to test\n",
        "THRESHOLDS = [0.05, 0.1, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50,\n",
        "              0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
        "\n",
        "# Detection parameters\n",
        "RELEASE_RATIO = 0.9\n",
        "HOP_MS = 40.0\n",
        "CHUNK_SIZE = 1280\n",
        "TARGET_RATE = 16000\n",
        "CAPTURE_SECONDS = 0  # Set to 0 to disable saving triggered audio\n",
        "\n",
        "# Working directory for extracted files (local to Colab instance)\n",
        "WORK_DIR = \"/content/negative_wavs\"\n",
        "\n",
        "print(\"Configuration loaded successfully!\")\n",
        "print(f\"Testing {len(THRESHOLDS)} thresholds: {THRESHOLDS}\")"
      ],
      "metadata": {
        "id": "config",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b18eb6-5464-49ef-d128-5203950748f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded successfully!\n",
            "Testing 19 thresholds: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Extract Negative WAV Files (if using ZIP)"
      ],
      "metadata": {
        "id": "section_extract"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if input is a zip file\n",
        "if NEGATIVE_WAVS_PATH.endswith('.zip'):\n",
        "    print(f\"Extracting {NEGATIVE_WAVS_PATH}...\")\n",
        "    !unzip -q \"{NEGATIVE_WAVS_PATH}\" -d \"{WORK_DIR}\"\n",
        "    print(f\"Extraction complete! Files extracted to {WORK_DIR}\")\n",
        "\n",
        "    # Count extracted files\n",
        "    wav_files = list(Path(WORK_DIR).rglob('*.wav'))\n",
        "    print(f\"Found {len(wav_files)} WAV files\")\n",
        "\n",
        "    AUDIO_DIR = WORK_DIR\n",
        "else:\n",
        "    # Assume it's already a directory\n",
        "    AUDIO_DIR = NEGATIVE_WAVS_PATH\n",
        "    wav_files = list(Path(AUDIO_DIR).rglob('*.wav'))\n",
        "    print(f\"Using directory: {AUDIO_DIR}\")\n",
        "    print(f\"Found {len(wav_files)} WAV files\")"
      ],
      "metadata": {
        "id": "extract_files",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdad4ef0-7864-491d-8577-c814ea0bfc91"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/curve_sweep/neg_wavs.zip...\n",
            "replace /content/negative_wavs/8555-284449-0011.wav? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "Extraction complete! Files extracted to /content/negative_wavs\n",
            "Found 2414 WAV files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Helper Classes and Functions"
      ],
      "metadata": {
        "id": "section_helpers"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PeakPicker:\n",
        "    \"\"\"\n",
        "    Simple peak-picking logic:\n",
        "    - Trigger when score crosses threshold from below.\n",
        "    - Arm next trigger when score falls below release_threshold.\n",
        "    \"\"\"\n",
        "    def __init__(self, threshold: float, release_ratio: float = 0.9):\n",
        "        self.threshold = threshold\n",
        "        self.release_threshold = threshold * release_ratio\n",
        "        self.armed = True\n",
        "\n",
        "    def step(self, score: float) -> bool:\n",
        "        if self.armed and score >= self.threshold:\n",
        "            self.armed = False\n",
        "            return True\n",
        "        if not self.armed and score < self.release_threshold:\n",
        "            self.armed = True\n",
        "        return False\n",
        "\n",
        "\n",
        "def read_wav_int16_mono(path: Path) -> tuple:\n",
        "    \"\"\"Read WAV file and return (samples_array, sample_rate)\"\"\"\n",
        "    with wave.open(str(path), \"rb\") as wf:\n",
        "        nchannels = wf.getnchannels()\n",
        "        sampwidth = wf.getsampwidth()\n",
        "        framerate = wf.getframerate()\n",
        "        nframes = wf.getnframes()\n",
        "        raw = wf.readframes(nframes)\n",
        "\n",
        "    if sampwidth != 2:\n",
        "        raise ValueError(f\"Only 16-bit WAV supported, got {sampwidth*8}-bit\")\n",
        "\n",
        "    arr = np.frombuffer(raw, dtype=np.int16)\n",
        "    if nchannels == 2:\n",
        "        arr = arr.reshape(-1, 2).mean(axis=1).astype(np.int16)\n",
        "    elif nchannels != 1:\n",
        "        raise ValueError(f\"Only mono/stereo supported, got {nchannels} channels\")\n",
        "\n",
        "    return arr, framerate\n",
        "\n",
        "\n",
        "def to_16k_linear_int16(samples: np.ndarray, source_rate: int) -> np.ndarray:\n",
        "    \"\"\"Simple linear resampling to 16kHz\"\"\"\n",
        "    if source_rate == TARGET_RATE:\n",
        "        return samples\n",
        "    ratio = TARGET_RATE / source_rate\n",
        "    new_len = int(len(samples) * ratio)\n",
        "    indices = np.linspace(0, len(samples) - 1, new_len)\n",
        "    return np.interp(indices, np.arange(len(samples)), samples).astype(np.int16)\n",
        "\n",
        "\n",
        "def extract_score(prediction, key: Optional[str]) -> Optional[float]:\n",
        "    \"\"\"Extract score from prediction\"\"\"\n",
        "    if key is None:\n",
        "        return None\n",
        "    if isinstance(prediction, dict):\n",
        "        val = prediction.get(key)\n",
        "        if val is None:\n",
        "            return None\n",
        "        if isinstance(val, (list, np.ndarray)):\n",
        "            return float(val[-1]) if len(val) > 0 else 0.0\n",
        "        return float(val)\n",
        "    return None\n",
        "\n",
        "\n",
        "print(\"Helper functions loaded successfully!\")"
      ],
      "metadata": {
        "id": "helpers",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962e2576-6028-4608-e934-7f56c9774a96"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Offline Detection Function"
      ],
      "metadata": {
        "id": "section_detection"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_offline_detection(audio_dir: Path, model_path: str, threshold: float,\n",
        "                         hop_ms: float, chunk_size: int) -> Dict:\n",
        "    \"\"\"\n",
        "    Run wake word detection on all WAV files in audio_dir with given threshold.\n",
        "    Returns dictionary with metrics.\n",
        "    \"\"\"\n",
        "    # Load model - fix: use correct parameter name\n",
        "    owwModel = Model(\n",
        "    wakeword_model_paths=[model_path] if model_path else None\n",
        ")\n",
        "\n",
        "    # Get model key\n",
        "    prediction_key = None\n",
        "\n",
        "    # Peak picker for this threshold\n",
        "    picker = PeakPicker(threshold, RELEASE_RATIO)\n",
        "\n",
        "    # Metrics\n",
        "    total_triggers = 0\n",
        "    total_seconds = 0.0\n",
        "    global_max_score = 0.0\n",
        "    file_count = 0\n",
        "\n",
        "    # Find all WAV files\n",
        "    files = sorted(audio_dir.rglob('*.wav'))\n",
        "\n",
        "    hop_samples = int((hop_ms / 1000.0) * TARGET_RATE)\n",
        "\n",
        "    for wav_file in files:\n",
        "        try:\n",
        "            arr, sr = read_wav_int16_mono(wav_file)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not read {wav_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "        if sr != TARGET_RATE:\n",
        "            arr = to_16k_linear_int16(arr, sr)\n",
        "\n",
        "        file_count += 1\n",
        "        total_seconds += len(arr) / TARGET_RATE\n",
        "\n",
        "        # Process in chunks with hopping\n",
        "        for start_idx in range(0, len(arr), hop_samples):\n",
        "            end_idx = min(start_idx + chunk_size, len(arr))\n",
        "            chunk = arr[start_idx:end_idx]\n",
        "\n",
        "            if len(chunk) < chunk_size:\n",
        "                chunk = np.pad(chunk, (0, chunk_size - len(chunk)), mode='constant')\n",
        "\n",
        "            try:\n",
        "                prediction = owwModel.predict(chunk)\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "            # Auto-detect key on first prediction\n",
        "            if prediction_key is None and isinstance(prediction, dict):\n",
        "                keys = list(prediction.keys())\n",
        "                prediction_key = keys[0] if keys else None\n",
        "\n",
        "            score = extract_score(prediction, prediction_key)\n",
        "            if score is None:\n",
        "                continue\n",
        "\n",
        "            global_max_score = max(global_max_score, score)\n",
        "\n",
        "            if picker.step(score):\n",
        "                total_triggers += 1\n",
        "\n",
        "    return {\n",
        "        'threshold': threshold,\n",
        "        'total_triggers': total_triggers,\n",
        "        'total_files': file_count,\n",
        "        'total_duration_seconds': total_seconds,\n",
        "        'total_duration_hours': total_seconds / 3600.0,\n",
        "        'global_max_score': global_max_score,\n",
        "        'triggers_per_hour': total_triggers / (total_seconds / 3600.0) if total_seconds > 0 else 0,\n",
        "        'release_threshold': threshold * RELEASE_RATIO\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"Detection function loaded successfully!\")"
      ],
      "metadata": {
        "id": "detection_function",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7002c60-3d53-4c68-fe4e-daa47d5da737"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection function loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Run Threshold Sweep\n",
        "\n",
        "This will test all thresholds and collect results. This may take several minutes depending on the number of files."
      ],
      "metadata": {
        "id": "section_sweep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "print(f\"Starting threshold sweep across {len(THRESHOLDS)} thresholds...\")\n",
        "print(f\"Processing {len(wav_files)} WAV files\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, threshold in enumerate(THRESHOLDS):\n",
        "    print(f\"\\n[{i+1}/{len(THRESHOLDS)}] Testing threshold: {threshold}\")\n",
        "\n",
        "    result = run_offline_detection(\n",
        "        audio_dir=Path(AUDIO_DIR),\n",
        "        model_path=MODEL_PATH,\n",
        "        threshold=threshold,\n",
        "        hop_ms=HOP_MS,\n",
        "        chunk_size=CHUNK_SIZE\n",
        "    )\n",
        "\n",
        "    results.append(result)\n",
        "    print(f\"  â†’ Triggers: {result['total_triggers']}, Max score: {result['global_max_score']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"Sweep complete! Tested {len(results)} thresholds.\")"
      ],
      "metadata": {
        "id": "run_sweep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed759af-d65e-4d00-b06f-e48a14ac9c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting threshold sweep across 19 thresholds...\n",
            "Processing 2414 WAV files\n",
            "============================================================\n",
            "\n",
            "[1/19] Testing threshold: 0.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Save Results to CSV"
      ],
      "metadata": {
        "id": "section_save"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CSV headers\n",
        "headers = [\n",
        "    'threshold',\n",
        "    'release_threshold',\n",
        "    'total_triggers',\n",
        "    'total_files',\n",
        "    'total_duration_seconds',\n",
        "    'total_duration_hours',\n",
        "    'global_max_score',\n",
        "    'triggers_per_hour'\n",
        "]\n",
        "\n",
        "# Write to CSV\n",
        "with open(OUTPUT_CSV_PATH, 'w', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(results)\n",
        "\n",
        "print(f\"Results saved to: {OUTPUT_CSV_PATH}\")\n",
        "print(f\"Total rows: {len(results)}\")"
      ],
      "metadata": {
        "id": "save_csv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Display Results Summary"
      ],
      "metadata": {
        "id": "section_summary"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load and display results\n",
        "df = pd.read_csv(OUTPUT_CSV_PATH)\n",
        "print(\"\\nRESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(df.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Find optimal threshold (minimum false positives)\n",
        "min_triggers_idx = df['total_triggers'].idxmin()\n",
        "optimal_threshold = df.loc[min_triggers_idx, 'threshold']\n",
        "min_triggers = df.loc[min_triggers_idx, 'total_triggers']\n",
        "\n",
        "print(f\"\\nOptimal threshold (min false positives): {optimal_threshold}\")\n",
        "print(f\"False positives at optimal: {min_triggers}\")\n",
        "print(f\"\\nCSV saved to Google Drive: {OUTPUT_CSV_PATH}\")"
      ],
      "metadata": {
        "id": "display_summary",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}